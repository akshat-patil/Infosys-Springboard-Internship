{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16bac73c",
   "metadata": {},
   "source": [
    "## Loading the CNN Daily Mail Dataset (Training and Validation sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e05fb28-519c-4520-87f9-7a934735b789",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "# Load the dataset\n",
    "dataset = datasets.load_dataset('cnn_dailymail', '3.0.0')\n",
    "\n",
    "train_data = dataset['train'].shuffle(seed=42).select(range(int(0.001 * len(dataset['train']))))\n",
    "val_data = dataset['validation'].shuffle(seed=42).select(range(int(0.001 * len(dataset['validation']))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab39b3c",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55f35624-23e2-48de-9e26-177167daca96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'article': \"By . Anthony Bond . PUBLISHED: . 07:03 EST, 2 March 2013 . | . UPDATED: . 08:07 EST, 2 March 2013 . Three members of the same family who died in a static caravan from carbon monoxide poisoning would have been unconscious 'within minutes', investigators said today. The bodies of married couple John and Audrey Cook were discovered alongside their daughter, Maureen, at the mobile home they shared on Tremarle Home Park in Camborne, west Cornwall. The inquests have now opened into the deaths last Saturday, with investigators saying the three died along with the family's pet dog, of carbon monoxide poisoning from a cooker. Tragic: The inquests have opened into the deaths of three members of the same family who were found in their static caravan last weekend. John and Audrey Cook are pictured . Awful: The family died following carbon monoxide poisoning at this caravan at the Tremarle Home Park in Camborne, Cornwall . It is also believed there was no working carbon monoxide detector in the static caravan. Cornwall Fire and Rescue Service said this would have resulted in the three being unconscious 'within minutes', . A spokesman for Cornwall coroner Dr Emma Carlyon confirmed the inquests were opened and adjourned yesterday afternoon. They will resume at a later date. Devon and Cornwall Police confirmed on Monday that carbon monoxide poisoning had been established as the cause of death. A police spokesman said the source of the poisoning was 'believed to be from incorrect operation of the gas cooker'. Poisoning: This woman left flowers outside the caravan following the deaths. It has emerged that the trio would have been unconscious 'within minutes' Touching: This tribute was left outside the caravan following news of the deaths . Early readings from experts at the site revealed a potentially lethal level of carbon monoxide present within the caravan at the time it was taken, shortly after the discovery of the bodies. Friends and neighbours have paid tribute to the trio. One . neighbour, Sonya Owen, 53, said: 'It's very distressing. I knew the . daughter, she was living her with her mum and dad. Everybody is really . upset.' Margaret Holmes, 65, who lived near the couple and their . daughter, said: 'They had lived here for around 40 years and they kept . themselves to themselves. 'I just can’t believe this has . happened, it is so sad and I am so shocked, I think we all are, you just . don’t expect this sort of thing to happen on your doorstep. 'Everyone will miss them, we used to chat a lot when we were both in the garden. 'I would just like to send my condolences to their family, I can’t imagine what they’re going through.' Nic Clark, 52, who was good friends with daughter Maureen, added: 'They were a lovely kind family, a great trio. 'Maureen . used to go out and walk her dog, a little Jack Russell, it is so sad . what has happened, I understand the dog went with them. 'They . will be sorely missed and I think everyone is just in shock at the . moment, I would like to send my condolences to the Cook family.'\", 'highlights': 'John and .\\nAudrey Cook were discovered alongside their daughter, Maureen .\\nThey were found at Tremarle Home Park in Cornwall .\\nInvestigators say the three died of carbon monoxide .\\npoisoning .', 'id': '08cf276c9eadb638e0c7fdc83ce0229c8af5d09b'}\n",
      "Average article length: 701.4250871080139\n",
      "Average summary length: 51.7595818815331\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0]) \n",
    "\n",
    "# Average word count in articles and summaries\n",
    "article_lengths = [len(sample['article'].split()) for sample in train_data]\n",
    "summary_lengths = [len(sample['highlights'].split()) for sample in train_data]\n",
    "\n",
    "print(\"Average article length:\", sum(article_lengths) / len(article_lengths))\n",
    "print(\"Average summary length:\", sum(summary_lengths) / len(summary_lengths))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7247316",
   "metadata": {},
   "source": [
    "## Data Cleaning and Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f5a2400-1646-45fc-8f2c-066e46ac5fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91862\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5418a7a4e2ae4e9a8c3d1acad8c11293",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/287 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b102e6fd30594583acdd1f011f7c65f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BartTokenizer\n",
    "import re\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
    "\n",
    "# Function to clean and tokenize data\n",
    "def preprocess_data(examples):\n",
    "    examples['article'] = [re.sub(r'\\s+', ' ', article) for article in examples['article']]\n",
    "    examples['highlights'] = [re.sub(r'\\s+', ' ', summary) for summary in examples['highlights']]\n",
    "\n",
    "    # Tokenize articles and summaries\n",
    "    inputs = tokenizer(examples['article'], truncation=True, padding='max_length', max_length=1024)\n",
    "    targets = tokenizer(examples['highlights'], truncation=True, padding='max_length', max_length=150)\n",
    "    return {'input_ids': inputs['input_ids'], 'attention_mask': inputs['attention_mask'], 'labels': targets['input_ids']}\n",
    "\n",
    "train_data = train_data.map(preprocess_data, batched=True)\n",
    "val_data = val_data.map(preprocess_data, batched=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b7b468",
   "metadata": {},
   "source": [
    "## Model Training using BART model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c33e9a5-7635-4f77-8e14-7ee003f56920",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91862\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of BartForConditionalGeneration were not initialized from the model checkpoint at facebook/bart-large-cnn and are newly initialized: ['model.shared.weight', 'model.encoder.embed_tokens.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following columns in the training set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: id, highlights, article. If id, highlights, article are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "C:\\Users\\91862\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 287\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 2\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 16\n",
      "  Total optimization steps = 27\n",
      "  Number of trainable parameters = 406290432\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 4:34:35, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.722975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.158800</td>\n",
       "      <td>1.138577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.172300</td>\n",
       "      <td>1.051491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: id, highlights, article. If id, highlights, article are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 13\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to ./results\\checkpoint-10\n",
      "Configuration saved in ./results\\checkpoint-10\\config.json\n",
      "Model weights saved in ./results\\checkpoint-10\\pytorch_model.bin\n",
      "tokenizer config file saved in ./results\\checkpoint-10\\tokenizer_config.json\n",
      "Special tokens file saved in ./results\\checkpoint-10\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: id, highlights, article. If id, highlights, article are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 13\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to ./results\\checkpoint-20\n",
      "Configuration saved in ./results\\checkpoint-20\\config.json\n",
      "Model weights saved in ./results\\checkpoint-20\\pytorch_model.bin\n",
      "tokenizer config file saved in ./results\\checkpoint-20\\tokenizer_config.json\n",
      "Special tokens file saved in ./results\\checkpoint-20\\special_tokens_map.json\n",
      "Deleting older checkpoint [results\\checkpoint-10] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: id, highlights, article. If id, highlights, article are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 13\n",
      "  Batch size = 2\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=27, training_loss=2.1936102266664856, metrics={'train_runtime': 17138.5169, 'train_samples_per_second': 0.05, 'train_steps_per_second': 0.002, 'total_flos': 1865877062418432.0, 'train_loss': 2.1936102266664856, 'epoch': 3.0})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BartForConditionalGeneration, Trainer, TrainingArguments\n",
    "\n",
    "# Loading BART model for summarization\n",
    "model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')\n",
    "\n",
    "# Set training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=2, \n",
    "    per_device_eval_batch_size=2,\n",
    "    weight_decay=0.01,\n",
    "    num_train_epochs=3,  \n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    save_steps=10,\n",
    "    save_total_limit=1,\n",
    "    gradient_accumulation_steps=16,  \n",
    "    fp16=False  \n",
    ")\n",
    "\n",
    "# Define the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=val_data,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77facfda",
   "metadata": {},
   "source": [
    "## Model Testing and Performance evaluation using BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "434f1b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from datasets import load_dataset\n",
    "from transformers import BartForConditionalGeneration, Trainer, TrainingArguments, BartTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3c0d7bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc7b009c190c4324b707f4443a5ad732",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loading the test dataset\n",
    "test_data = dataset['test'].shuffle(seed=42).select(range(int(0.001 * len(dataset['test']))))\n",
    "test_data = test_data.map(preprocess_data, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1033686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining BLEU evaluation function\n",
    "def compute_bleu(predictions, references):\n",
    "    reference_lists = [[ref.split()] for ref in references]\n",
    "    prediction_lists = [pred.split() for pred in predictions]\n",
    "    return corpus_bleu(reference_lists, prediction_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f34a1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Trainer for evaluation\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    eval_dataset=test_data,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "caa3ad93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: id, highlights, article. If id, highlights, article are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11\n",
      "  Batch size = 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results:\n",
      "eval_loss: 0.9898132085800171\n",
      "eval_runtime: 90.9034\n",
      "eval_samples_per_second: 0.121\n",
      "eval_steps_per_second: 0.066\n"
     ]
    }
   ],
   "source": [
    "# Perform evaluation on the test dataset\n",
    "results = trainer.evaluate()\n",
    "# Display the results\n",
    "print(\"Evaluation Results:\")\n",
    "for key, value in results.items():\n",
    "    print(f\"{key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b972fc",
   "metadata": {},
   "source": [
    "## Data Exploration after training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6162222f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article:\n",
      "Arsene Wenger admits he is concerned Theo Walcott’s confidence is plummeting after his struggles with England this week. The Arsenal manager will have a heart-to-heart chat with the forward ahead of Saturday’s crunch top-four clash against Liverpool. Walcott was hauled off after 55 minutes of England’s 1-1 draw in Italy on Tuesday night. Theo Walcott struggled for England and Arsene Wenger admits he is concerned by the winger's confidence . Walcott was replaced by Ross Barkley after just 55 minutes of England's 1-1 draw against Italy on Tuesday . 2 - Premier League goals for Walcott this season - his average haul per season during his time at Arsenal is 5.6. It was the latest disappointment in a difficult season for the 26-year-old, who has struggled for game time since returning from a long-term lay-off due to a serious knee injury. With Alex Oxlade-Chamberlain out of Liverpool’s visit due to a hamstring strain, and Danny Welbeck a major doubt after sustaining a knee problem on international duty, Walcott could start on Saturday. But Wenger said: ‘Yes, I’m worried about Theo’s confidence. He’s sensitive and I’m a bit concerned about the damage that game can have on his mind. Walcott could face Liverpool on Saturday with Alex Oxlade-Chamberlain injured and Danny Welbeck a doubt . ‘He’s not completely there yet (after the injury). But being exposed like that, people have a harsh judgement on him that is not deserved because he does well. ‘At the moment he is frustrated, but that is normal. I will speak with him, but I think he is strong enough. ‘I will see what state of mind he is in. We always have a word, if it is a positive experience or a negative experience, you ask “how did it go?”. We always speak about the last game. ‘He is not fragile mentally, he is strong mentally but he is disappointed because when you come back from an injury you always think you are ready. ‘He needs patience. He is at the moment not in his best mood. ‘He has big confidence in himself and he has gone through some difficult periods in his life and he has always come out with strength.’ Arsenal boss Wenger says he will speak with Walcott but believes the Gunners winger is 'strong enough' Walcott found himself playing in the No 10 role for England in Turin — a role he is not accustomed to. And Wenger admitted he was surprised to see the pacy forward in such an unfamiliar position. ‘Have I ever seen him play No 10 in training or anything? No,’ said Wenger. ‘Theo’s strength is the quality of his movements, he wants to go to get on the end of things. He’s not a guy who provides. ‘I don’t think it was the intention of Roy Hodgson to play him there. It’s maybe because Wayne Rooney took the initiative during the game to play higher up and tell Theo to drop back. ‘I didn’t see Roy Hodgson in the game stand up to say “Walcott, you come and play in midfield and Rooney you go up front”. That’s an initiative they took on the pitch.’ Walcott aims a shot at goal during England's friendly against Italy at the Juventus Stadium in Turin . Walcott was starting his first international game in 18 months having injured his cruciate ligaments . Meanwhile, Wenger insists there are fundamental flaws in FA chairman Greg Dyke’s proposal to increase the number of required homegrown players in Premier League squads to 12. Dyke believes increasing the number of British players in squads will help contribute to a more successful England team. But Wenger said: ‘I believe we are in a top level competition and you earn your right through the quality of your performance rather than your place of birth. ‘Secondly, I’m happy to, and would like to contribute to the quality of the English national team, but you have two questions you can raise before that. ‘First of all between 1966 and 1996 there were no foreign players in England and it didn’t improve too much the performances of the national team. ‘Secondly, if between the ages of 16 and 21 the England youth teams win every single competition in Europe then there is something we have to do because they are not getting their chance at the top level. Wenger believes there are flaws in FA Chairman Greg Dyke’s proposal to increase the homegrown quota . ‘That is not the case, on the contrary. I think between 16 and 21 the English youth teams, until now, have not performed. So that’s the heart of the problem. ‘Let’s get better at that level, then if there is a problem integrating these players in the top teams, we have to do something about it. ‘I think today you have to be very brave to integrate young players in the top teams because the pressure is very high. I still believe when they are good enough, they play. ‘You speak about Raheem Sterling and Harry Kane. Nobody stops the quality, no matter where they are from. So let’s focus on that first.’\n",
      "\n",
      "True Summary:\n",
      "Arsene Wenger will have chat with Theo Walcott ahead of Arsenal clash . Walcott was substituted after 55 minutes of England's draw with Italy . Arsenal boss is Wenger is concerned by the winger's confidence . The Gunners take on Liverpool at the Emirates Stadium on Saturday .\n",
      "\n",
      "Predicted Summary:\n",
      "Theo Walcott was replaced after 55 minutes of England's 1-1 draw with Italy on Tuesday. Arsene Wenger says he will have a heart-to-heart chat with the forward ahead of Arsenal's clash with Liverpool on Saturday. The Gunners boss says he is concerned about Walcott's confidence after his struggles with England. Walcott could start against Liverpool with Alex Oxlade-Chamberlain out injured and Danny Welbeck a major doubt.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "sample_idx = random.randint(0, len(test_data) - 1)\n",
    "sample = test_data[sample_idx]\n",
    "\n",
    "print(\"Article:\")\n",
    "print(sample['article'])\n",
    "print(\"\\nTrue Summary:\")\n",
    "print(sample['highlights'])\n",
    "\n",
    "inputs = tokenizer(sample['article'], return_tensors='pt', truncation=True, padding='max_length', max_length=1024).to(model.device)\n",
    "\n",
    "output = model.generate(inputs['input_ids'], attention_mask=inputs['attention_mask'], max_length=150)\n",
    "\n",
    "predicted_summary = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"\\nPredicted Summary:\")\n",
    "print(predicted_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "29c3e1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a paragraph to summarize: Artificial intelligence (AI) is the simulation of human intelligence processes by machines, especially computer systems. These processes include learning, reasoning, and self-correction. AI can be classified into narrow AI, which is specialized for specific tasks, and general AI, which aims to perform any intellectual task that a human can do. As AI technology advances, it has the potential to revolutionize various industries, including healthcare, finance, and transportation.\n",
      "\n",
      "Generated Summary:\n",
      "Artificial intelligence (AI) is the simulation of human intelligence processes by machines, especially computer systems. These processes include learning, reasoning, and self-correction. As AI technology advances, it has the potential to revolutionize various industries, including healthcare, finance, and transportation.\n"
     ]
    }
   ],
   "source": [
    "# Function to generate summary for a user input\n",
    "def generate_summary(user_input):\n",
    "    inputs = tokenizer(user_input, return_tensors='pt', truncation=True, padding='max_length', max_length=1024).to(model.device)\n",
    "\n",
    "    summary_ids = model.generate(inputs['input_ids'], attention_mask=inputs['attention_mask'], max_length=150)\n",
    "\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "user_input = input(\"Enter a paragraph to summarize: \")\n",
    "\n",
    "summary = generate_summary(user_input)\n",
    "print(\"\\nGenerated Summary:\")\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87de79fc",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "86ab2a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in C:/Users/91862/Desktop/Text_Sum_Infosys/saved_model\\config.json\n",
      "Model weights saved in C:/Users/91862/Desktop/Text_Sum_Infosys/saved_model\\pytorch_model.bin\n",
      "tokenizer config file saved in C:/Users/91862/Desktop/Text_Sum_Infosys/saved_model\\tokenizer_config.json\n",
      "Special tokens file saved in C:/Users/91862/Desktop/Text_Sum_Infosys/saved_model\\special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('C:/Users/91862/Desktop/Text_Sum_Infosys/saved_model\\\\tokenizer_config.json',\n",
       " 'C:/Users/91862/Desktop/Text_Sum_Infosys/saved_model\\\\special_tokens_map.json',\n",
       " 'C:/Users/91862/Desktop/Text_Sum_Infosys/saved_model\\\\vocab.json',\n",
       " 'C:/Users/91862/Desktop/Text_Sum_Infosys/saved_model\\\\merges.txt',\n",
       " 'C:/Users/91862/Desktop/Text_Sum_Infosys/saved_model\\\\added_tokens.json')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.save_pretrained(\"C:/Users/91862/Desktop/Text_Sum_Infosys/saved_model\")\n",
    "tokenizer.save_pretrained(\"C:/Users/91862/Desktop/Text_Sum_Infosys/saved_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95737158",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
